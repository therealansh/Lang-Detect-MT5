{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "XNLI-MT5Small-Finetuned.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# mT5 Transformer finetuned on XNLI dataset for Language Prediction\n",
    "\n",
    "- XNLI is an evaluation corpus for language transfer and cross-lingual sentence classification in 15 languages.\n",
    "- mT5 is pretrained on the mC4 corpus, covering 101 languages\n",
    "- mT5 was only pre-trained on mC4 excluding any supervised training. Therefore, this model has to be fine-tuned before it is useable on a downstream task. For Example: Language Classification\n",
    "- `data` folder contains the `xnli.test.tsv` and `xnli.dev.tsv`. These files can also be downloaded from [here.](https://cims.nyu.edu/~sbowman/xnli/)\n",
    "- `output` folder contains the outputs produced by the trained model. I trained the model on a TPU, GPU can also be used(slower) for fine tuning.\n",
    "- The trained model can be found on this [drive link.](https://drive.google.com/drive/folders/1VBtbUt66v_gAwM6o0vPVUgqgeGrKbkMk?usp=sharing)\n",
    "\n",
    "### Steps:\n",
    "1. Run the cells one by one.\n",
    "2. If using TPU, set the flag `ON_TPU` to true.\n",
    "3. Also if using TPU, set the `MAIN_DIR` and `PATH_TO_DATA` to your respective GCS Bucket\n",
    "4. If you are not training the model again, download the model from [drive link.](https://drive.google.com/drive/folders/1VBtbUt66v_gAwM6o0vPVUgqgeGrKbkMk?usp=sharing) and run the last cell for the predictions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCi0QcOtJhon",
    "outputId": "fba414d3-24cd-4a78-a262-b34fb7e9718f"
   },
   "source": [
    "!pip install t5"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set `ON_TPU` flag to true, if using TPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "dtyq62yMJxKA",
    "outputId": "08856b8a-528d-48fe-a092-7c112ef1df5e"
   },
   "source": [
    "import functools\n",
    "from functools import partial\n",
    "import tensorflow._api.v2.compat.v1 as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import t5\n",
    "import t5.models\n",
    "from t5.models import MtfModel\n",
    "import seqio\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "ON_TPU = False      #Change in case if TPU is present\n",
    "tf.test.gpu_device_name()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set `PATH_TO_DATA` to your GCS Bucket(if using TPU)/Local Path where the XNLI data is present."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRzYaT9XKJ7r",
    "outputId": "6029a2f7-0e5f-40bb-8500-a1d2d7c77c1c"
   },
   "source": [
    "#Reads Data and store in Pandas Dataframe\n",
    "\n",
    "PATH_TO_DATA = \"data/\"\n",
    "train_df = pd.read_csv(PATH_TO_DATA+\"xnli.test.tsv\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(PATH_TO_DATA+\"xnli.dev.tsv\",sep=\"\\t\")\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZVx2tvArKoSc"
   },
   "source": [
    "def create_data(old,new):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to create a new `csv` file by concatenating the `sentence1` and `sentence2` fields\n",
    "    :param old: Path to old csv\n",
    "    :param new: Path of new csv\n",
    "    :return: new csv is created\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(old,sep='\\t')\n",
    "    df = df[['language','sentence1','sentence2']]\n",
    "    sent1 = df[['language','sentence1']].rename(columns={\"sentence1\":\"input\"})\n",
    "    sent2 = df[['language','sentence2']].rename(columns={\"sentence2\":\"input\"})\n",
    "    final = pd.concat([sent1,sent2],ignore_index=True)\n",
    "    final['input'] = 'input: '+final.input\n",
    "    final = final.drop_duplicates()\n",
    "    final = final.sample(frac=1)\n",
    "    final.to_csv(new,index=False,header=False)\n",
    "    print(f'Shape: {final.shape}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task Registration\n",
    "1. A `Task` is a dataset along with preprocessing functions and evaluation metrics.\n",
    "2. For this notebook, we register a new task in the `TaskRegistry` called `lang_classify`\n",
    "3. There are predefined tasks as well, but for a downstream task like QnA and Language Identification(as done here), a new task needs to be registered first.\n",
    "#### Set `MAIN_DIR` path to your GCS Bucket, if using TPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fU2Vs8Y0Kr_N",
    "outputId": "9932ce0c-0bb3-4c78-d78f-ebeaa1b320bc"
   },
   "source": [
    "MAIN_DIR = \"\"         #Add path to a gcs bucket if using TPU\n",
    "\n",
    "xnli_csv_path = {\n",
    "    \"train\":\"train.csv\",\n",
    "    \"test\": \"test.csv\"\n",
    "}\n",
    "\n",
    "def xnli_dataset_fn(split, shuffle_files=False):\n",
    "  if MAIN_DIR==\"\":\n",
    "    ds = tf.data.TextLineDataset(xnli_csv_path[split])\n",
    "  else:\n",
    "    ds = tf.data.TextLineDataset(MAIN_DIR+xnli_csv_path[split])\n",
    "  ds = ds.map(\n",
    "      functools.partial(tf.io.decode_csv, record_defaults=[\"\", \"\"],\n",
    "                        field_delim=\",\"),\n",
    "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  ds = ds.map(lambda *ex: dict(zip([\"language\", \"input\"], ex)))\n",
    "  return ds\n",
    "\n",
    "def lang_preprocessor(data):\n",
    "        return data.map(lambda ex:{\"inputs\":ex[\"input\"],\"targets\": ex[\"language\"]}, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "DEFAULT_VOCAB = t5.data.SentencePieceVocabulary(\"gs://t5-data/vocabs/mc4.250000.100extra/sentencepiece.model\")\n",
    "\n",
    "DEFAULT_OUTPUT_FEATURES = {\n",
    "    \"inputs\":\n",
    "        seqio.Feature(\n",
    "            vocabulary=DEFAULT_VOCAB, add_eos=True,required=False),\n",
    "    \"targets\":\n",
    "        seqio.Feature(\n",
    "            vocabulary=DEFAULT_VOCAB, add_eos=True)\n",
    "}\n",
    "\n",
    "task = \"lang_classify\"\n",
    "\n",
    "seqio.TaskRegistry.remove(task)\n",
    "seqio.TaskRegistry.add(\n",
    "    task,\n",
    "    source=seqio.FunctionDataSource(\n",
    "        dataset_fn=xnli_dataset_fn,\n",
    "        splits=[\"train\", \"test\"],\n",
    "        ),\n",
    "    preprocessors=[\n",
    "        lang_preprocessor,\n",
    "        seqio.preprocessors.tokenize_and_append_eos,\n",
    "    ],\n",
    "    postprocess_fn=t5.data.postprocessors.lower_text,\n",
    "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
    "    output_features=DEFAULT_OUTPUT_FEATURES,\n",
    "  )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Creation and PreProcessing\n",
    "1. We create two new files `train.csv` and `test.csv` with the help of  `create_data` function.\n",
    "2. These files consist only the relevant data that is of use to us i.e [language] and the [sentence1, sentence2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxxV9azYLMul",
    "outputId": "fa8b0ccf-1266-4b73-decb-fe2c1e5255e0"
   },
   "source": [
    "create_data(PATH_TO_DATA+'xnli.test.tsv',\"train.csv\")\n",
    "create_data(PATH_TO_DATA+'xnli.dev.tsv',\"test.csv\")\n",
    "print(pd.read_csv(\"train.csv\").shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training\n",
    "\n",
    "1. mT5 small Transformer is trained with the following specifications.\n",
    "    - Learning Rate = 0.003\n",
    "    - Batch Size = 32 if GPU or else 128 if TPU\n",
    "    - EPOCH = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofQq0_uBLX8u",
    "outputId": "8bc3503a-006b-4108-e7b9-d9518b16c4bd"
   },
   "source": [
    "PRE_TRAINED_MODEL = \"gs://t5-data/pretrained_models/mt5/small\"\n",
    "LR = 0.003\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TPU_TOPOLOGY = \"v2-8\"\n",
    "TPU_ADDRESS = None\n",
    "\n",
    "if ON_TPU:\n",
    "    BATCH_SIZE = 128\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "        TPU_ADDRESS = tpu.get_master()\n",
    "        print('Running on TPU:', TPU_ADDRESS)\n",
    "    except ValueError as e:\n",
    "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "    tf.enable_eager_execution()\n",
    "    tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
    "\n",
    "n = pd.read_csv(\"train.csv\").shape[0]\n",
    "EPOCH = 5\n",
    "ft_steps = int(n/BATCH_SIZE)*EPOCH\n",
    "\n",
    "if MAIN_DIR==\"\":\n",
    "  MODEL_DIR = \"models/\"\n",
    "else:\n",
    "  MODEL_DIR = MAIN_DIR+\"models/\"\n",
    "\n",
    "model = MtfModel(MODEL_DIR,\n",
    "                   tpu=TPU_ADDRESS,\n",
    "                 tpu_topology=TPU_TOPOLOGY,\n",
    "                   model_parallelism=1,\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   sequence_length={\"inputs\": 64, \"targets\": 15},\n",
    "                   learning_rate_schedule=LR,\n",
    "                   save_checkpoints_steps=5000,\n",
    "                    keep_checkpoint_max= 16 if ON_TPU else None,\n",
    "                   iterations_per_loop=300 if ON_TPU else 100)\n",
    "\n",
    "model.finetune(\n",
    "      mixture_or_task_name=task,\n",
    "      pretrained_model_dir=PRE_TRAINED_MODEL,\n",
    "      finetune_steps=ft_steps,\n",
    "      split=\"train\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation\n",
    "We now evaluate on the validation sets of the tasks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eal-C6Vy-kC3"
   },
   "source": [
    "model.batch_size = BATCH_SIZE*4\n",
    "SUMM_DIR = \"output/\" if MAIN_DIR==\"\" else MAIN_DIR+\"output/\"\n",
    "model.eval(\n",
    "    \"lang_classify\",\n",
    "    summary_dir=SUMM_DIR,\n",
    "    checkpoint_steps=-1,\n",
    "    split=\"test\"\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Metrics\n",
    "Here we evaluate the model on different metrics like, precision, recall, f1. And finally take a look into a classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X3GH41Vl_Grs"
   },
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def get_prediction(output_dir,task_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function to get the prediction files\n",
    "    :param output_dir: Directory where the output of the .eval() were saved.\n",
    "    :param task_name: Task name\n",
    "    \"\"\"\n",
    "\n",
    "    def _prediction_file_to_ckpt(path):\n",
    "        return int(path.split(\"_\")[-2])\n",
    "    prediction_files = tf.io.gfile.glob(os.path.join(output_dir,\"%s_*_predictions\"%task_name))\n",
    "    if len(prediction_files) == 0: return None\n",
    "    return sorted(prediction_files, key=_prediction_file_to_ckpt)[-1]\n",
    "\n",
    "def evaluation(output_dir,task_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Gives the evaluation of the model trained. i.e. precision, recall and f1\n",
    "    :param output_dir: Directory where the output of the .eval() were saved.\n",
    "    :param task_name: Task name\n",
    "    :return: Classification report\n",
    "    \"\"\"\n",
    "\n",
    "    pred_fn = get_prediction(output_dir,task_name)\n",
    "    if not pred_fn: return None,None,None\n",
    "    with tf.io.gfile.GFile(pred_fn) as p:\n",
    "        preds = [line.strip() for line in p]\n",
    "\n",
    "    with tf.io.gfile.GFile(os.path.join(output_dir,\"%s_targets\" % task_name)) as t:\n",
    "        targets = [line.strip() for line in t]\n",
    "\n",
    "    with tf.io.gfile.GFile(os.path.join(output_dir,\"%s_inputs\" % task_name)) as i:\n",
    "        inputs = [eval(line).decode('utf-8') for line in i]\n",
    "\n",
    "    p,r,f1,_ = precision_recall_fscore_support(targets, preds,average='micro')\n",
    "    print(f'precison: {p} \\nrecall: {r} \\nf1: {f1}\\n')\n",
    "    print()\n",
    "    print(classification_report(targets,preds))\n",
    "\n",
    "evaluation(SUMM_DIR, \"lang_classify\")\n"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precison: 0.9972889933128501 \n",
      "recall: 0.9972889933128501 \n",
      "f1: 0.9972889933128501\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ar       1.00      1.00      1.00      3320\n",
      "          bg       1.00      1.00      1.00      3320\n",
      "          de       1.00      1.00      1.00      3320\n",
      "          el       1.00      1.00      1.00      3320\n",
      "          en       0.99      1.00      0.99      3320\n",
      "          es       1.00      1.00      1.00      3320\n",
      "          fr       1.00      1.00      1.00      3320\n",
      "          hi       1.00      0.98      0.99      3320\n",
      "          ru       1.00      1.00      1.00      3320\n",
      "          sw       1.00      1.00      1.00      3319\n",
      "          th       1.00      1.00      1.00      3320\n",
      "          tr       1.00      1.00      1.00      3320\n",
      "          ur       0.98      1.00      0.99      3319\n",
      "          vi       1.00      1.00      1.00      3320\n",
      "          zh       1.00      1.00      1.00      3319\n",
      "\n",
      "    accuracy                           1.00     49797\n",
      "   macro avg       1.00      1.00      1.00     49797\n",
      "weighted avg       1.00      1.00      1.00     49797\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9Zx5xNlqAeFF"
   },
   "source": [
    "if ON_TPU:\n",
    "    %reload_ext tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"$MODEL_DIR\" --port=0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predictions\n",
    "1. Finally, the model is used to predict on the outside data.\n",
    "2. `load_model` returns the latest model and `predictions` return the prediction of the input.\n",
    "<br/><br/>\n",
    "*Note Do add the task \"lang_classify\" in the `TaskRegistry`. This can be done by running the cell labeled as `Task Registration`*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#[NOTE] : Do register the new task i.e. \"lang_classify\" before running this cell. Do run the `Task Registration` cell.\n",
    "\n",
    "def load_model(path):\n",
    "\n",
    "    \"\"\"\n",
    "    Loads the current model\n",
    "    :param path: path to model\n",
    "    :return: MtfModel\n",
    "    \"\"\"\n",
    "\n",
    "    return MtfModel(path,\n",
    "                   tpu=None,\n",
    "                   model_parallelism=1,\n",
    "                   sequence_length={\"inputs\": 64, \"targets\": 15})\n",
    "\n",
    "def predictions(inputs,model=None):\n",
    "    \"\"\"\n",
    "    Get predictions of the input.\n",
    "    :param inputs: List of Strings or a String\n",
    "    :param model: Model used to predict\n",
    "    :return: Predictions in (predd.txt)\n",
    "    \"\"\"\n",
    "\n",
    "    if type(inputs) == str:\n",
    "        inputs = [inputs]\n",
    "\n",
    "    with open('inputs.txt', \"w\") as f:\n",
    "        for inp in inputs:\n",
    "            f.write(\"input: %s\\n\" % inp.lower())\n",
    "\n",
    "    model.predict(\n",
    "          input_file='inputs.txt',\n",
    "          output_file='predd.txt',\n",
    "          temperature=0,\n",
    "      )\n",
    "\n",
    "\n",
    "model = load_model(MODEL_DIR)\n",
    "inputs = [\n",
    "    \"चलो पार्क चलते हैं\",\n",
    "    \"Hãy đến công viên\",\n",
    "    \"Vamos a aparcar\",\n",
    "    \"Пойдем в парк\",\n",
    "          ]\n",
    "predictions(inputs,model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}